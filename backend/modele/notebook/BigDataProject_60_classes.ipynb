{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2NXKEQ_55Xm",
        "outputId": "c635003f-9a9a-475e-c413-91cdf0a6a55c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Collecting ndjson\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Installing collected packages: ndjson\n",
            "Successfully installed ndjson-0.3.1\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.1 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import json\n",
        "!pip install ndjson\n",
        "!mkdir -p quickdraw_data\n",
        "import os\n",
        "import wandb\n",
        "import ndjson\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "import cv2\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80KtH_ay7P5p",
        "outputId": "98f5003a-a96e-4bc9-b560-6ab66597d219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Téléchargement : ship\n",
            "Téléchargement : bird\n",
            "Téléchargement : camel\n",
            "Téléchargement : cat\n",
            "Téléchargement : dolphin\n",
            "Téléchargement : crab\n",
            "Téléchargement : fish\n",
            "Téléchargement : flamingo\n",
            "Téléchargement : hedgehog\n",
            "Téléchargement : raccoon\n",
            "Téléchargement : lion\n",
            "Téléchargement : octopus\n",
            "Téléchargement : whale\n",
            "Téléchargement : shark\n",
            "Téléchargement : rhinoceros\n",
            "Téléchargement : rabbit\n",
            "Téléchargement : pig\n",
            "Téléchargement : crocodile\n",
            "Téléchargement : cow\n",
            "Téléchargement : elephant\n",
            "Téléchargement : alarm%20clock\n",
            "Téléchargement : anvil\n",
            "^C\n",
            "Téléchargement : axe\n",
            "^C\n",
            "Téléchargement : backpack\n",
            "Téléchargement : baseball%20bat\n"
          ]
        }
      ],
      "source": [
        "# Les 10 premières catégories disponibles dans le dataset\n",
        "categories = [\n",
        "    # Animaux\n",
        "    \"ship\",\n",
        "    \"bird\",\n",
        "    \"camel\",\n",
        "    \"cat\",\n",
        "    \"dolphin\",\n",
        "    \"crab\",\n",
        "    \"fish\",\n",
        "    \"flamingo\",\n",
        "    \"hedgehog\",\n",
        "    \"raccoon\",\n",
        "    \"lion\",\n",
        "    \"octopus\",\n",
        "    \"whale\",\n",
        "    \"shark\",\n",
        "    \"rhinoceros\",\n",
        "    \"rabbit\",\n",
        "    \"pig\",\n",
        "    \"crocodile\",\n",
        "    \"cow\",\n",
        "    \"elephant\",\n",
        "\n",
        "    # Objets\n",
        "    \"alarm%20clock\",\n",
        "    \"anvil\",\n",
        "    \"axe\",\n",
        "    \"backpack\",\n",
        "    \"baseball%20bat\",\n",
        "    \"bed\",\n",
        "    \"belt\",\n",
        "    \"bicycle\",\n",
        "    \"cell%20phone\",\n",
        "    \"flip%20flops\",\n",
        "    \"headphones\",\n",
        "    \"tshirt\",\n",
        "    \"flower\",\n",
        "    \"eyeglasses\",\n",
        "    \"harp\",\n",
        "    \"hexagon\",\n",
        "    \"key\",\n",
        "    \"ladder\",\n",
        "    \"knife\",\n",
        "    \"fork\",\n",
        "\n",
        "    # Aliments\n",
        "    \"apple\",\n",
        "    \"banana\",\n",
        "    \"birthday%20cake\",\n",
        "    \"blueberry\",\n",
        "    \"bread\",\n",
        "    \"broccoli\",\n",
        "    \"carrot\",\n",
        "    \"cookie\",\n",
        "    \"donut\",\n",
        "    \"grapes\",\n",
        "    \"hamburger\",\n",
        "    \"hot%20dog\",\n",
        "    \"ice%20cream\",\n",
        "    \"lollipop\",\n",
        "    \"mushroom\",\n",
        "    \"pear\",\n",
        "    \"pineapple\",\n",
        "    \"pizza\",\n",
        "    \"strawberry\",\n",
        "    \"watermelon\",\n",
        "]\n",
        "\n",
        "# Création du dossier de données\n",
        "os.makedirs(\"quickdraw_data\", exist_ok=True)\n",
        "\n",
        "# Téléchargement automatique via wget\n",
        "for category in categories:\n",
        "    url = f\"https://storage.googleapis.com/quickdraw_dataset/full/simplified/{category}.ndjson\"\n",
        "    filename = f\"quickdraw_data/{category}.ndjson\"\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"Téléchargement : {category}\")\n",
        "        !wget -q -O {filename} {url}\n",
        "    else:\n",
        "        print(f\"Déjà téléchargé : {category}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdM9eTOIqTIV",
        "outputId": "6e312d0c-f357-4232-a3ac-6dd02d1b7953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVbfuvjK7a4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2811f8ac-ba75-477e-e332-8e642192a14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images : (190000, 28, 28)\n",
            "Total labels : (190000,)\n"
          ]
        }
      ],
      "source": [
        "#Parser et convertir les 1000 premiers dessins reconnus des 10 catégories déjà téléchargées (en .ndjson)\n",
        "# en images 28x28, et les stocker dans deux arrays : images (numpy) et labels (str).\n",
        "\n",
        "# Fonction pour convertir un dessin (strokes) en image PIL 28x28\n",
        "def draw_strokes(drawing, size=28, lw=3):\n",
        "    img = Image.new(\"L\", (256, 256), color=0)  # 256x256 pour avoir de la marge\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    for stroke in drawing:\n",
        "        points = list(zip(stroke[0], stroke[1]))\n",
        "        draw.line(points, fill=255, width=lw)\n",
        "\n",
        "    img = img.resize((size, size), Image.Resampling.LANCZOS)\n",
        "    return np.array(img)\n",
        "\n",
        "\n",
        "\n",
        "def dilate_image(img, kernel_size=2, iterations=1):\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "    return cv2.dilate(img, kernel, iterations=iterations)\n",
        "\n",
        "def erode_image(img, kernel_size=2, iterations=1):\n",
        "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
        "    return cv2.erode(img, kernel, iterations=iterations)\n",
        "\n",
        "\n",
        "# Parser et convertir les 100 premiers dessins reconnus\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for category in categories:\n",
        "    path = f\"quickdraw_data/{category}.ndjson\"\n",
        "    try:\n",
        "        with open(path) as f:\n",
        "            data = ndjson.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Fichier manquant pour {category}, ignoré.\")\n",
        "        continue\n",
        "\n",
        "    count = 0\n",
        "    for sample in data:\n",
        "        if sample[\"recognized\"]:\n",
        "            img = draw_strokes(sample[\"drawing\"])\n",
        "            images.append(img)\n",
        "            labels.append(category)\n",
        "            count += 1\n",
        "        if count >= 10000:  # Load 1000 samples per category\n",
        "            break\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Total images :\", images.shape)\n",
        "print(\"Total labels :\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ_tlWbFJ6jv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b730d4c6-dc94-4866-fdc2-22e8d2e01cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.49.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.22.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (4.23.0)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.32.3)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (13.9.4)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.28.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.20.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (1.17.2)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from comet_ml) (3.1.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.18.4->comet_ml) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.3.2->comet_ml) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema!=3.1.0,>=2.6.0->comet_ml) (4.13.2)\n",
            "Downloading comet_ml-3.49.10-py3-none-any.whl (727 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dulwich-0.22.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading python_box-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: everett, semantic-version, python-box, dulwich, configobj, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.3.2\n",
            "    Uninstalling python-box-7.3.2:\n",
            "      Successfully uninstalled python-box-7.3.2\n",
            "Successfully installed comet_ml-3.49.10 configobj-5.0.9 dulwich-0.22.8 everett-3.1.0 python-box-6.1.0 semantic-version-2.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: tensorflow, torch, keras, sklearn.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/judale/gribouillon/cc387a96cf9f4cb0a4ba9a264c600e34\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml\n",
        "from comet_ml import Experiment\n",
        "from comet_ml.integration.pytorch import log_model\n",
        "\n",
        "experiment = Experiment(\n",
        "    api_key=\"zaG3cbShNIuBY5f3JXvcTMNJa\",\n",
        "    project_name=\"gribouillon\",\n",
        "    workspace=\"judale\"\n",
        ")\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i3sKsy0qTIV"
      },
      "source": [
        "# visualisations des fonctions d'érosions et dilatations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT3owV7VqTIW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "1e67dd12-3296-40bc-9169-3f27b2fa4d49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# Image originale\n",
        "idx = random.randint(0, len(images) - 1)\n",
        "original = images[idx]\n",
        "\n",
        "# Application de la dilatation et de l’érosion\n",
        "dilated = dilate_image(original, kernel_size=2)\n",
        "eroded  = erode_image(original, kernel_size=2)\n",
        "\n",
        "# Affichage\n",
        "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axs[0].imshow(original, cmap='gray')\n",
        "axs[0].set_title('Original')\n",
        "axs[1].imshow(dilated, cmap='gray')\n",
        "axs[1].set_title('Dilatée')\n",
        "axs[2].imshow(eroded, cmap='gray')\n",
        "axs[2].set_title('Érodée')\n",
        "for ax in axs:\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6I5xNdN7y_L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "0ae33f53-fdbc-432f-cb8b-9dee9e1a52dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualisez une image random\n",
        "import random\n",
        "\n",
        "idx = random.randint(0, len(images) - 1)\n",
        "plt.imshow(images[idx], cmap=\"gray\")\n",
        "plt.title(labels[idx])\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxLJTUID9yFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5825c864-d37f-4f23-f90e-e66c9435e161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Catégories encodées : [np.str_('bird'), np.str_('camel'), np.str_('cat'), np.str_('cow'), np.str_('crab'), np.str_('crocodile'), np.str_('dolphin'), np.str_('elephant'), np.str_('fish'), np.str_('flamingo'), np.str_('hedgehog'), np.str_('lion'), np.str_('octopus'), np.str_('pig'), np.str_('rabbit'), np.str_('raccoon'), np.str_('rhinoceros'), np.str_('shark'), np.str_('whale')]\n",
            "Nombre de classes : 19\n",
            "Données prêtes pour l'entraînement.\n"
          ]
        }
      ],
      "source": [
        "# Normalisation : on ramène les valeurs des pixels entre 0 et 1\n",
        "images = images.astype(\"float32\") / 255.0\n",
        "images = np.expand_dims(images, axis=1)  # PyTorch : (N, 1, 28, 28)\n",
        "\n",
        "# Encodage des labels (ex: 'cat' -> 3, 'dog' -> 5, etc.)\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "print(\"Catégories encodées :\", list(label_encoder.classes_))\n",
        "print(\"Nombre de classes :\", len(label_encoder.classes_))\n",
        "\n",
        "\n",
        "# Split des données\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_encoded, test_size=0.2, stratify=labels_encoded, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
        "\n",
        "# Conversion en tenseurs\n",
        "X_train = torch.tensor(X_train)\n",
        "X_val   = torch.tensor(X_val)\n",
        "X_test  = torch.tensor(X_test)\n",
        "\n",
        "y_train = torch.tensor(y_train)\n",
        "y_val   = torch.tensor(y_val)\n",
        "y_test  = torch.tensor(y_test)\n",
        "\n",
        "# Création des datasets\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset   = TensorDataset(X_val, y_val)\n",
        "test_dataset  = TensorDataset(X_test, y_test)\n",
        "\n",
        "# Création des DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "print(\"Données prêtes pour l'entraînement.\")\n",
        "\n",
        "#On a 8 classes alors qu'on devrait en avoir 10 il faut donc prendre la variable \"classes\" dans le modèle CNN pour être sûr de ne pas avoir des classes des fichiers .ndjson sont en erreur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywxs8oAM_mkt"
      },
      "outputs": [],
      "source": [
        "# CNN simple avec PyTorch, inspiré de LeNet-5, adapté aux images 28×28 en niveaux de gris\n",
        "class BetterCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(BetterCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # (1, 28, 28) -> (32, 28, 28)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),  # (32, 28, 28)\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # (32, 14, 14)\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # (64, 14, 14)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # (64, 14, 14)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  # (64, 7, 7)\n",
        "            nn.Dropout(0.3006002871157536),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3006002871157536),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = BetterCNN(num_classes=len(label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFWXovPzAKQQ"
      },
      "outputs": [],
      "source": [
        "# Transforme les tableaux images et labels en un Dataset PyTorch, puis les séparer en train, val et test\n",
        "\n",
        "class QuickDrawDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transforms.Compose([\n",
        "               transforms.ToPILImage(),\n",
        "               transforms.RandomRotation(10),  # Rotation aléatoire de 10 degrés\n",
        "               transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Translation aléatoire\n",
        "               transforms.ToTensor()\n",
        "           ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # The line below was causing the problem\n",
        "        # image = torch.tensor(image).unsqueeze(0)  # Shape: (1, 28, 28)\n",
        "        # We already have (1, 28, 28) from previous opera*=tions\n",
        "        image = torch.tensor(image)  # Keep the original image shape (1, 28, 28)\n",
        "        label = torch.tensor(label).long()\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeF-yfilBEaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe05f85-f6de-4f49-80f9-37bce22df279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 152000, Val: 19000, Test: 19000\n"
          ]
        }
      ],
      "source": [
        "# Séparation train/val/test\n",
        "\n",
        "# Encodage des labels texte en entiers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Split 80% train, 10% val, 10% test\n",
        "# Use labels_np instead of labels_encoded for stratify\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X27i2FyDBT33"
      },
      "outputs": [],
      "source": [
        "# Création des DataLoader\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = QuickDrawDataset(X_train, y_train)\n",
        "val_dataset = QuickDrawDataset(X_val, y_val)\n",
        "test_dataset = QuickDrawDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBNiH-E9Bd1K"
      },
      "outputs": [],
      "source": [
        "# Initialisation de l’entraînement - Définir modèle, loss et optimizer\n",
        "model = BetterCNN(num_classes=len(label_encoder.classes_)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5) # L2 regularization\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=1)  # Reduce LR if val loss plateaus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cjOXZxmBxMx"
      },
      "outputs": [],
      "source": [
        "# Intégration avec Weights & Biases - Initialisation comet\n",
        "\n",
        "lr=0.001\n",
        "num_epochs = 50\n",
        "\n",
        "experiment.set_name(f\"Modèle classe animaux\")\n",
        "\n",
        "experiment.log_parameters({\n",
        "    \"learning_rate\": lr,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"epochs\": num_epochs,\n",
        "    \"num_classes\": len(set(labels))\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcCmcsz9CrVB",
        "outputId": "06947a5c-09ed-4ef1-ae05-0eb378bb6a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/20] Train Acc: 60.25% | Val Acc: 73.23%\n",
            "[2/20] Train Acc: 70.36% | Val Acc: 77.45%\n",
            "[3/20] Train Acc: 73.11% | Val Acc: 78.83%\n",
            "[4/20] Train Acc: 74.86% | Val Acc: 80.10%\n",
            "[5/20] Train Acc: 75.69% | Val Acc: 81.19%\n",
            "[6/20] Train Acc: 76.39% | Val Acc: 81.67%\n",
            "[7/20] Train Acc: 76.96% | Val Acc: 82.34%\n",
            "[8/20] Train Acc: 77.53% | Val Acc: 82.57%\n",
            "[9/20] Train Acc: 77.87% | Val Acc: 83.12%\n",
            "[10/20] Train Acc: 78.31% | Val Acc: 82.82%\n",
            "[11/20] Train Acc: 78.51% | Val Acc: 83.31%\n",
            "[12/20] Train Acc: 78.84% | Val Acc: 83.18%\n",
            "[13/20] Train Acc: 79.03% | Val Acc: 83.32%\n",
            "[14/20] Train Acc: 79.02% | Val Acc: 83.47%\n",
            "[15/20] Train Acc: 79.42% | Val Acc: 83.92%\n",
            "[16/20] Train Acc: 79.47% | Val Acc: 84.06%\n",
            "[17/20] Train Acc: 79.59% | Val Acc: 83.72%\n",
            "[18/20] Train Acc: 79.76% | Val Acc: 84.31%\n",
            "[19/20] Train Acc: 79.93% | Val Acc: 84.20%\n",
            "[20/20] Train Acc: 80.21% | Val Acc: 84.11%\n",
            "Early stopping.\n"
          ]
        }
      ],
      "source": [
        "# boucle entrainement\n",
        "\n",
        "best_val_acc = 0\n",
        "patience = 2\n",
        "wait = 0\n",
        "\n",
        "train_accs, val_accs = [], []\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    correct = total = 0\n",
        "    train_loss = 0 # Initialize train_loss for each epoch\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0) # Accumulate loss\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader.dataset) # Calculate average train loss\n",
        "    train_acc = 100 * correct / total\n",
        "    train_accs.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    val_loss = 0 # Initialize val_loss for each epoch\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels) # Calculate loss for validation\n",
        "            val_loss += loss.item() * images.size(0) # Accumulate loss\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset) # Calculate average validation loss\n",
        "    val_acc = 100 * correct / total\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    print(f\"[{epoch+1}/20] Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "    experiment.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "    experiment.log_metric(\"val_loss\", val_loss, step=epoch)\n",
        "    experiment.log_metric(\"train_acc\", train_acc, step=epoch)\n",
        "    experiment.log_metric(\"val_acc\", val_acc, step=epoch)\n",
        "\n",
        "    scheduler.step(val_loss) # Step the scheduler with validation loss\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        wait = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    else:\n",
        "        wait += 1\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ded_K-5eIYJt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a86ce71-3976-43b2-d099-333ce2d311b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.42%\n"
          ]
        }
      ],
      "source": [
        "# Évaluation sur le test set\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_acc = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "experiment.log_metric(\"test_accuracy\", test_acc)\n",
        "log_model(experiment, model, model_name=\"CNN_QuickDraw\")\n",
        "\n",
        "# fonction d’affichage de courbes\n",
        "\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_accuracy\"], label=\"Val\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history[\"loss\"], label=\"Train\")\n",
        "    plt.plot(history.history[\"val_loss\"], label=\"Val\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am8Z4daWIcfY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ce7fab-a932-472c-c511-acec85dbc09f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle sauvegardé dans quickdraw_animal.pth\n"
          ]
        }
      ],
      "source": [
        "#  Sauvegarde du modèle entraîné (.pth)\n",
        "\n",
        "model_path = \"quickdraw_animal.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Modèle sauvegardé dans {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J59EaLqzIkeW"
      },
      "outputs": [],
      "source": [
        "# Arrêt du tracking Weights & Biases\n",
        "\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgZ6APxBIoMQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, optimizer, train_loader, val_loader, criterion, epochs=3):\n",
        "    model.to(device)\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x_batch)\n",
        "            loss = criterion(preds, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Évaluation validation\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in val_loader:\n",
        "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
        "                outputs = model(x_val)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += y_val.size(0)\n",
        "                correct += (predicted == y_val).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "    return best_acc\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Paramètres Optuna à tester\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
        "    dropout = trial.suggest_float(\"dropout\", 0.3, 0.7)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "\n",
        "    # Conversion numpy -> torch.tensor\n",
        "    X_train_tensor = torch.tensor(X_train).float()\n",
        "    y_train_tensor = torch.tensor(y_train).long()\n",
        "    X_val_tensor   = torch.tensor(X_val).float()\n",
        "    y_val_tensor   = torch.tensor(y_val).long()\n",
        "\n",
        "    # Création des jeux de données\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Définition du modèle (exemple CNN simple avec dropout variable)\n",
        "    class TunedCNN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(TunedCNN, self).__init__()\n",
        "            self.features = nn.Sequential(\n",
        "                nn.Conv2d(1, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(32, 32, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2),\n",
        "                nn.Dropout(dropout),\n",
        "\n",
        "                nn.Conv2d(32, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(64, 64, 3, padding=1),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(2),\n",
        "                nn.Dropout(dropout),\n",
        "            )\n",
        "            self.classifier = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(64 * 7 * 7, 128),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(128, len(label_encoder.classes_))  # nombre de classes\n",
        "            )\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = self.features(x)\n",
        "            x = self.classifier(x)\n",
        "            return x\n",
        "\n",
        "    model = TunedCNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Entraînement rapide (3 epochs max pour Optuna)\n",
        "    best_acc = 0\n",
        "    for epoch in range(3):\n",
        "        model.train()\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Évaluation sur validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                outputs = model(xb)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += yb.size(0)\n",
        "                correct += (predicted == yb).sum().item()\n",
        "\n",
        "        acc = correct / total\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "\n",
        "    return best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyvkM81pAZ-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d04ec4b-06ea-48b5-e446-9da215321d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type de X_train : <class 'numpy.ndarray'>\n",
            "Shape de X_train : (152000, 1, 28, 28)\n",
            "Type de y_train : <class 'numpy.ndarray'>\n",
            "Shape de y_train : (152000,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Type de X_train :\", type(X_train))\n",
        "print(\"Shape de X_train :\", getattr(X_train, 'shape', 'no shape'))\n",
        "print(\"Type de y_train :\", type(y_train))\n",
        "print(\"Shape de y_train :\", getattr(y_train, 'shape', 'no shape'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZdmbBVh9Y_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69476bff-c552-4aeb-88ea-5b880489872f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-27 08:23:51,078] A new study created in memory with name: no-name-ce1ef47d-061b-4716-8d4d-e1b93b72a799\n",
            "[I 2025-05-27 08:24:24,280] Trial 0 finished with value: 0.7072631578947368 and parameters: {'lr': 0.0002855339397042051, 'dropout': 0.6457111584222855, 'batch_size': 64}. Best is trial 0 with value: 0.7072631578947368.\n",
            "[I 2025-05-27 08:24:52,699] Trial 1 finished with value: 0.6954210526315789 and parameters: {'lr': 0.0003220008646002111, 'dropout': 0.6119663877229842, 'batch_size': 128}. Best is trial 0 with value: 0.7072631578947368.\n",
            "[I 2025-05-27 08:25:41,557] Trial 2 finished with value: 0.7622631578947369 and parameters: {'lr': 0.0003245772338030808, 'dropout': 0.4960566590800759, 'batch_size': 32}. Best is trial 2 with value: 0.7622631578947369.\n",
            "[I 2025-05-27 08:26:09,194] Trial 3 finished with value: 0.05263157894736842 and parameters: {'lr': 0.00775159771137797, 'dropout': 0.3333417698816321, 'batch_size': 128}. Best is trial 2 with value: 0.7622631578947369.\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "print(\"Best accuracy:\", study.best_value)\n",
        "print(\"Best params:\", study.best_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okGYIVC31fV3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}